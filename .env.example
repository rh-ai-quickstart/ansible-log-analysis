OPENAI_API_TOKEN=TODO
OPENAI_API_ENDPOINT=TODO_URL_and/v1 # https://llama-4-scout-17b-16e-w4a16-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com:443/v1
OPENAI_MODEL=TODO # llama-4-scout-17b-16e-w4a16
OPENAI_TEMPERATURE=0.7

# Optional: Separate model for tool calling
# Only set these if your main model (OPENAI_MODEL) does not support tool calling
# If set, the system will use this model for operations that require tool calling support
# OPENAI_API_TOKEN_WITH_TOOL_CALLING=your_api_token_here
# OPENAI_API_ENDPOINT_WITH_TOOL_CALLING=https://your-endpoint.com/v1
# OPENAI_MODEL_WITH_TOOL_CALLING=your_model_name

LANGSMITH_TRACING=false
LANGSMITH_API_KEY=
LANGSMITH_PROJECT=
DATABASE_URL=postgresql+asyncpg://user:password@localhost:5432/logsdb
BACKEND_URL=http://localhost:8000
SENTENCE_TRANSFORMER_MODEL_NAME=Qwen/Qwen3-Embedding-0.6B
CLUSTERING_ALGORITHM=meanshift

# Optional: Remote embeddings API configuration for clustering
# If these are set, the system will use a remote OpenAI-compatible embeddings API
# instead of loading the SentenceTransformer model locally
# EMBEDDINGS_LLM_API_KEY=your_api_key_here
# EMBEDDINGS_LLM_URL=http://localhost:8080
# EMBEDDINGS_LLM_MODEL_NAME=your_model_name

TMP_CLUSTER_MODEL_PATH=clustering_model.joblib

COLLECTOR_ENDPOINT=http://localhost:6006/v1/traces
PROD_CORS_ORIGIN=http://localhost:3000


# ============================================================================
# RAG (Retrieval-Augmented Generation) Configuration
# ============================================================================
EMBEDDINGS_LLM_URL=http://localhost:8080
# Optional config for remote services that require an API key:
EMBEDDINGS_LLM_API_KEY=

# RAG Service URL (microservice endpoint)
# Backend communicates with RAG service via HTTP
# Default: http://alm-rag:8002 (for Kubernetes) or http://localhost:8002 (for local)
RAG_SERVICE_URL=http://localhost:8002
# Enable/disable RAG functionality (default: true)
RAG_ENABLED=true

# Data directory for RAG index and knowledge base
# Default: ./data
DATA_DIR=./data

# Knowledge base directory (where PDF files are stored)
# Default: ./data/knowledge_base
KNOWLEDGE_BASE_DIR=./data/knowledge_base

# Embedding Service Configuration (TEI - text-embeddings-inference)
# Model is hardcoded to nomic-ai/nomic-embed-text-v1.5 (no config needed)
# Service URL is optional - defaults to http://alm-embedding:8080 (local cluster service)
# Only set this if you need to override the default URL
# EMBEDDINGS_LLM_URL=http://alm-embedding:8080

# RAG query configuration (optional, has defaults)
RAG_TOP_K=5
RAG_TOP_N=1
RAG_SIMILARITY_THRESHOLD=0.6


# ============================================================================
# Loki Configuration
# ============================================================================

LOKI_MCP_SERVER_URL=http://localhost:8080/stream
LOKI_URL=http://localhost:3100


# ============================================================================
# Service Configuration
# ============================================================================
LOG_LEVEL=INFO